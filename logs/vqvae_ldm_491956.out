Job started on Tue Sep  9 04:16:40 PM EDT 2025
Running on node: cia011
Running on accelerator=gpu, devices=None
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 3, 64, 64) = 12288 dimensions.
making attention of type 'vanilla' with 512 in_channels
loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth
VQLPIPSWithDiscriminator running with hinge loss.
Monitoring val/rec_loss as checkpoint metric.
Merged modelckpt-cfg: 
{'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': 'logs/2025-09-09T16-16-56_vq-f4/checkpoints', 'filename': '{epoch:06}', 'verbose': True, 'save_last': True, 'monitor': 'val/rec_loss', 'save_top_k': 3}}
Removed 1 files from filelist during filtering.
Removed 0 files from filelist during filtering.
Removed 1 files from filelist during filtering.
Removed 0 files from filelist during filtering.
#### Data #####
train, WrappedDataset, 1152196
validation, WrappedDataset, 48627
accumulate_grad_batches = 2
Setting learning rate to 1.08e-04 = 2 (accumulate_grad_batches) * 1 (num_gpus) * 12 (batchsize) * 4.50e-06 (base_lr)
Removed 1 files from filelist during filtering.
Removed 0 files from filelist during filtering.
Removed 1 files from filelist during filtering.
Removed 0 files from filelist during filtering.
lr_d 0.000108
lr_g 0.000108
Summoning checkpoint.

Job finished on Tue Sep  9 04:18:44 PM EDT 2025
